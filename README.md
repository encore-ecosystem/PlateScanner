<h1 style="text-align: center; margin-bottom: 40px;">PlateScanner</h1>

<p style="text-align: center;">
    <img alt="Logo" height="800" src="\articles\Assets\third_out_cropped.png" width="1200"/>
</p>


Добро пожаловать в **PlateScanner**! Этот проект разработан для эффективного и точного распознавания номерных знаков. Наша цель – предоставить надежное решение, которое использует современные алгоритмы для распознавания и извлечения информации о номерных знаках из изображений и видео.

# Начало работы 
Для начала работы с **PlateScanner** убедитесь, что у вас установлена версия ***Python 3.12*** или выше. Этот проект требует нескольких зависимостей, которые можно легко управлять с помощью **Poetry**. Ниже приведены шаги для настройки проекта:

### Предварительные требования
- **Python 3.12** или выше
- Менеджер пакетов **Poetry**

## Шаги установки
1. **Клонируйте репозиторий** на свой локальный компьютер:
```bash
git clone https://github.com/encore-ecosystem/PlateScanner.git
```

2. **Перейдите в каталог** проекта:
```bash
cd PlateScanner
```

3. **Установите зависимости** с помощью Poetry:
```bash
pip install poetry # Если не установлен менеджер пакетов Poetry
poetry shell # Запуск виртуального окружения Poetry
poetry install
```
# Запуск приложения
Чтобы запустить приложение **PlateScanner**, используйте следующую команду:
```bash
python main.py
```
После этого вы должны увидеть сообщение **"PlateScanner"** с возможностью выбора дальнейших действий, как показано на изображении:

<img alt="intro1" src=".\articles\Assets\intro1.png"/>

**PlateScanner** предоставляет возможность предсказывать ограничивающие рамки (bounding boxes) на изображении, а также валидировать нейронные сети. Для этого необходимо выполнить небольшую предварительную настройку. Проект предлагает предобученные модели, которые можно загрузить по следующей ссылке: **[Models](https://disk.yandex.ru/d/s3NrpFxzpE02YQ)**. Скачайте интересующие вас модели в папку _PlateScanner/models_.

## Predict

После загрузки моделей выберите цифру 1 для режима предсказания (**predict**). Далее по порядку указывайте следующие параметры:
 - **< путь_к_входной_папке>** : Укажите абсолютный путь к папке, содержащей входные изображения или видео. **Важно отметить**, что указанная папка должна соответствовать следующей структуре: _input_path/test/images_. То есть, если вы указываете путь _PlateScanner/dataset_, изображения будут загружаться из папки _PlateScanner/dataset/test/images_.


 - **< путь_к_выходной_папке >** : Укажите абсолютный путь к папке, где будут сохранены результаты.


 - **< confidence >** : (Необязательный) Укажите уровень доверия для детекции в процентах.


 - **< model >** : Выберите номер модели, которую вы хотите использовать для предсказания (в этом списке будут отображены нейронные сети, которые вы скачали из предоставленной ссылки).

 Нажмите Enter, и начнётся процесс предсказания. После его завершения вы сможете просмотреть результаты в указанной вами выходной папке.

## Validate

Проект **PlateScanner** предоставляет пользователям специализированную валидацию. Подробнее о ней вы можете ознакомиться, перейдя по следующей ссылке: **[Новые подходы к валидации нейронных сетей в задаче детекции ГРЗ](\articles\Новые подходы к валидации нейронных сетей в          задаче детекции ГРЗ.md)**.

Чтобы запустить процесс валидации, выберите цифру 2. Далее по порядку указывайте следующие параметры:
- **< путь_к_входной_папке>** : Укажите абсолютный путь к папке, содержащей входные изображения с разметкой. Важно отметить, что указанная папка должна соответствовать следующей структуре: _input_path/valid/images_ и _input_path/valid/labels_. То есть, если вы указываете путь _PlateScanner/dataset_, изображения будут валидироваться из папки _PlateScanner/dataset/valid/images_ по разметке из _PlateScanner/dataset/valid/labels_. Важное замечание: если вы хотите провалидировать модель формата OBB, то разметка labels также должна быть формата OBB. Более подробно про OBB-разметку можно ознакомиться [здесь](https://docs.ultralytics.com/ru/tasks/obb/).


 - **< путь_к_выходной_папке >** : Укажите абсолютный путь к папке, где будут сохранены результаты.

 
 - **< model >** : Выберите номер модели, которую вы хотите использовать для предсказания (в этом списке будут отображены нейронные сети, которые вы скачали из предоставленной ссылки). Важно отметить, что значение _confidence_ для модели выставляется автоматически на уровне 6%. Если вы хотите изменить это значение, то поменяйте гиперпараметр DEFAULT_CONFIDENCE_LEVEL, который находится в PlateScanner/src/\__init\__.py.
 

 - **< criteria >** : Выберите номер критерия, который вас интересует. Результаты __confusion matrix__ будут строиться по указанным вами критериям. Если критерий не имеет значения, нажмите Enter _(any)_.


 - **< num of images >** : Выберите количество изображений, на которые вы хотели бы взглянуть, чтобы оценить, как нейронная сеть справилась с разметкой по указанным критериям. Будут использованы первые _n_ указанных изображений. Если вы хотите просмотреть все изображения, просто нажмите Enter. 

Результаты работы валидации и __confusion matrix__ можно будет найти в указанной вами выходной папке.

# Метрики нейронных сетей

Мы предоставляем пользователю результаты валидации на таргетовом датасете, состоящем из 24 разносортных изображений при фиксированном _confidence_ = 6%.

| **Версия модели**     | **Confidence** | **TP** | **FN** | **FP** | **Precision** | **Recall** | **F1-Score** | **Обработка изображения; <br/>sec / frame**  |
|-----------------------|----------------|--------|--------|--------|---------------|------------|---------------|:---------------------------------------:|
| yolo11n-obb          | 0,06           |   18   |   57   |   4    |    0,81818    |   0,24000  |    0,37113    |                 0,4484                  |
| yolov5nu             | 0,06           |   40   |   35   |   20   |    0,66667    |   0,53333  |    0,59259    |                 0,1873                  |
| yolo11n              | 0,06           |   46   |   29   |   5    |    0,90196    |   0,61333  |    0,73016    |                 0,4525                  |
| yolo11n-obbv2        | 0,06           |   56   |   19   |   21   |    0,72727    |   0,74667  |    0,73684    |                 0,2058                  |
| yolo11x              | 0,06           |   55   |   20   |   3    |    0,94828    |   0,73333  |    0,82707    |                 0,6579                  |


А также при __Precision__ > 90%:

| Версия модели      | Confidence | TP | FN | FP | Precision | Recall  | F1-Score |
|--------------------|------------|----|----|----|-----------|---------|----------|
| yolo11n-obb        | 0,43       | 10 | 65 | 1  | 0,90909   | 0,13333 | 0,23256  |
| yolov5nu           | 0,27       | 25 | 50 | 1  | 0,96154   | 0,33333 | 0,49505  |
| yolo11n-obbv2      | 0,54       | 35 | 40 | 2  | 0,94595   | 0,46667 | 0,62500  |
| yolo11n            | 0,14       | 42 | 33 | 2  | 0,95455   | 0,56000 | 0,70588  |
| yolo11x            | 0,07       | 55 | 20 | 2  | 0,96491   | 0,73333 | 0,83333  |

# Лицензия

Доступ к программному обеспечению предоставляется в соответствии с [EULA](LICENSE).